{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.interpolate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ad225c7b7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcoffea\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcoffea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalysis_objects\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mJaggedCandidateArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoffea\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nobackup/analysis/conda/uprootenv/lib/python3.6/site-packages/coffea/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlookup_tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manalysis_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstriped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nobackup/analysis/conda/uprootenv/lib/python3.6/site-packages/coffea/lookup_tools/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextractor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mextractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nobackup/analysis/conda/uprootenv/lib/python3.6/site-packages/coffea/lookup_tools/extractor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mroot_converters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_histo_root_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nobackup/analysis/conda/uprootenv/lib/python3.6/site-packages/coffea/lookup_tools/evaluator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjme_standard_function\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjme_standard_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjersf_lookup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjersf_lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mjec_uncertainty_lookup\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjec_uncertainty_lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m lookup_types = {'dense_lookup': dense_lookup,\n",
      "\u001b[0;32m~/nobackup/analysis/conda/uprootenv/lib/python3.6/site-packages/coffea/lookup_tools/jec_uncertainty_lookup.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minterp1d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.interpolate'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from coffea import hist\n",
    "from coffea.analysis_objects import JaggedCandidateArray\n",
    "import coffea.processor as processor\n",
    "from awkward import JaggedArray\n",
    "import numpy as np\n",
    "import glob as glob\n",
    "import itertools\n",
    "import json\n",
    "import uproot_methods\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at ProcessorABC to see the expected methods and what they are supposed to do\n",
    "class JetMassProcessor(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        dataset_axis = hist.Cat(\"dataset\", \"Primary dataset\")\n",
    "\n",
    "        pt_axis = hist.Bin(\"pt\", r\"$p_{T}$ [GeV]\", \n",
    "                           np.array([0,5,10,15,20,25,30,35,40,45,50,60,70,80,90,\n",
    "                                     100,120,140,160,180,\n",
    "                                     200,250,300,350,400,450,500,\n",
    "                                     600,700,800,900,1000,\n",
    "                                     1500,2000,3000,4000,5000]))\n",
    "        m_axis = hist.Bin(\"m\", r\"$p_{T}$ [GeV]\", 200, 0, 500)\n",
    "        dr_axis = hist.Bin(\"dr\", r\"$\\Delta r$\", 80, 0, 0.8)\n",
    "        \n",
    "        self._accumulator = processor.dict_accumulator({\n",
    "            'pt':hist.Hist(\"Counts\", dataset_axis, pt_axis),\n",
    "            'm':hist.Hist(\"Counts\", dataset_axis, m_axis),\n",
    "            'pt_v_m':hist.Hist(\"Counts\", dataset_axis, pt_axis, m_axis )\n",
    "            'dr':hist.Hist(\"Counts\", dataset_axis, dr_axis),\n",
    "            'cutflow': processor.defaultdict_accumulator(int)\n",
    "        })\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._accumulator\n",
    "    \n",
    "    def process(self, df):\n",
    "        output = self.accumulator.identity()\n",
    "\n",
    "        #print(\"1\")\n",
    "        dataset = df['dataset']\n",
    "        Jets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nJet'],\n",
    "            pt=df['FatJet_pt'] * (1 - df['FatJet_rawFactor']),\n",
    "            eta=df['FatJet_eta'],\n",
    "            phi=df['FatJet_phi'],\n",
    "            mass=df['FatJet_mass'],\n",
    "            jetId=df['FatJet_jetId']\n",
    "            )        \n",
    "        GenJets = JaggedCandidateArray.candidatesfromcounts(\n",
    "            df['nGenJetAK8'],\n",
    "            pt=df['GenJetAK8_pt'],\n",
    "            eta=df['GenJetAK8_eta'],\n",
    "            phi=df['GenJetAK8_phi'],\n",
    "            mass=df['GenJetAK8_mass']\n",
    "            )\n",
    "\n",
    "        evtweights = df[\"Generator_weight\"].reshape(-1, 1).flatten()\n",
    "        output['cutflow']['all events'] += Jets.size\n",
    "\n",
    "        jetId_cut = (Jets.jetId > 0)\n",
    "        Jets = Jets[jetId_cut]\n",
    "        output['cutflow']['>=1 with loose id'] += jetId_cut.any().sum()        \n",
    "        \n",
    "        pairing = Jets.p4.cross(GenJets.p4, nested=True)\n",
    "        metric = pairing.i0.delta_r(pairing.i1)\n",
    "        \n",
    "        index_of_minimized = metric.argmin()\n",
    "        dr_cut = (metric[index_of_minimized] < 0.8)\n",
    "        best_pairings_that_pass_dr_cut = pairing[index_of_minimized][dr_cut]\n",
    "        genrecos = best_pairings_that_pass_dr_cut.flatten(axis=1)\n",
    "        #print(\"genrecos shape:\", genrecos.shape)\n",
    "        ptresponse = genrecos.i0.pt / genrecos.i1.pt\n",
    "        mresponse = genrecos.i0.m / genrecos.i1.m\n",
    "        msdresponse =  \n",
    "        \n",
    "        output['pt'].fill(dataset=dataset,\n",
    "                            pt=Jets.pt.flatten())\n",
    "        output['eta'].fill(dataset=dataset, \n",
    "                                 eta=Jets.eta.flatten())\n",
    "        output['r_pt_ptveta'].fill( dataset=dataset, pt=genrecos.i1.pt.flatten(), eta=genrecos.i1.eta.flatten(), r=ptresponse.flatten())\n",
    "        return output\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        return output\n",
    "\n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the sample metadat\n",
    "\n",
    "with open(\"DYJetsToLLM-50TuneCUETP8M113TeV-madgraphMLM-pythia8RunIISummer16MiniAODv3-PUMoriond17_ext2-v2.txt\") as f:\n",
    "    filenames = f.readlines().rstrip()\n",
    "    for fi in filenames:\n",
    "        fi = 'root://cmsxrootd.fnal.gov//' + fi\n",
    "        \n",
    "print(filenames)\n",
    "fileset = {\"DY\":filenames}\n",
    "\n",
    "tstart = time.time() \n",
    "output = processor.run_uproot_job(fileset,\n",
    "                                  treename='Events',\n",
    "                                  processor_instance=FancyJECL2L3Processor(),\n",
    "                                  executor=processor.futures_executor,\n",
    "                                  executor_args={'workers': 4, 'flatten': True},\n",
    "                                  chunksize=500000,\n",
    "                                 )\n",
    "\n",
    "\n",
    "elapsed = time.time() - tstart\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cache1 = {}\n",
    "#Ttest = uproot.open('/mnt/cms-data/store/group/lpctlbsm/NanoAODJMAR_2019_V1/Production/CRAB/DYJetsToLL_M-50_HT-800to1200_TuneCP5_13TeV-madgraphMLM-pythia8/DYJetsToLLM-50HT-800to1200TuneCP513TeV-madgraphMLM-pythia8RunIIFall17MiniAODv2-PU2017/190312_200548/0000/nano102x_on_mini94x_2017_mc_NANO_9.root')['Events']\n",
    "#Ttest.arrays(\"*\",cache=cache1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fonts (from https://stackoverflow.com/questions/3899980/how-to-change-the-font-size-on-a-matplotlib-plot)\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 18\n",
    "BIGGER_SIZE = 24\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#H2 = H.reshape( (len(ptbins)-1)*(len(mbins)-1), (len(ptbins)-1)*(len(mbins)-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
